# 1.12 结论

本章介绍了一些概念，并提供了一个定量框架，我们将在全书中展开。从上一版开始，能效是性能的永恒伴侣。

在第二章中，我们从内存系统设计这个最重要的领域开始。我们将研究一系列的技术，这些技术合谋使内存看起来无限大，同时又尽可能地快。(附录B为没有太多经验和背景的读者提供了关于缓存的介绍性材料）。在后面的章节中，我们将看到硬件和软件的合作已经成为高性能内存系统的关键，就像它对高性能流水线一样。本章还包括虚拟机，这是一种越来越重要的保护技术。

在第三章中，我们研究了ILP，其中流水线是最简单和最常见的形式。利用ILP是构建高速单处理器的最重要技术之一。第3章首先对基本概念进行了广泛的讨论，使你为这两章所研究的广泛思想做好准备。第三章使用的例子横跨约40年，从最早的超级计算机之一（IBM 360/91）到2017年市场上最快的处理器。它强调了所谓的利用ILP的动态或运行时方法。它还谈到了ILP思想的局限性，并介绍了多线程，这在第四章和第五章都有进一步的发展。附录C为没有很多流水线经验和背景的读者提供了关于流水线的介绍性材料。(我们希望它能成为许多读者的复习资料，包括那些我们的介绍性课本《计算机组织与设计：硬件/软件界面》的读者。）。

第四章解释了利用数据级并行的三种方法。最经典和最古老的方法是矢量结构，我们从这里开始，奠定了SIMD设计的原则。(附录G对矢量结构进行了更深入的研究。)接下来我们解释了当今大多数台式微处理器中的SIMD指令集扩展。第三部分是对现代图形处理单元（GPU）如何工作的深入解释。大多数GPU的描述都是从程序员的角度写的，这通常掩盖了计算机的真正工作原理。这一部分从内部人士的角度解释GPU，包括GPU术语和更传统的架构术语之间的映射。

第五章重点讨论了使用多个处理器或多处理器实现更高的性能问题。多处理器不是使用并行性来重叠单个指令，而是使用并行性来允许多个指令流在不同处理器上同时执行。我们的重点是多处理器的主要形式，即共享内存多处理器，尽管我们也介绍了其他类型，并讨论了任何多处理器中出现的广泛问题。这里我们再次探讨了各种技术，重点是 20 世纪 80 年代和 90 年代首次提出的重要观点。

第六章介绍了集群，然后深入探讨了计算机架构师帮助设计的WSCs。WSCs的设计者是超级计算机先驱的继承者，如Seymour Cray，因为他们正在设计极端的计算机。WSCs包含数以万计的服务器，设备和容纳它们的建筑耗资近2亿美元。前面几章所关注的性价比和能源效率问题适用于WSCs，量化的决策方法也适用于WSCs。

第七章是本版的新内容。它介绍了特定领域的架构，鉴于摩尔定律和Dennard定律的结束，这是提高性能和能源效率的唯一途径。它提供了如何构建有效的特定领域架构的指南，介绍了令人兴奋的深度神经网络领域，描述了最近的四个例子，它们采取了非常不同的方法来加速神经网络，然后比较了它们的性价比。

本书在网上附带了大量的材料（详见前言），既是为了降低成本，也是为了向读者介绍各种高级课题。图1.25显示了它们的全部内容。书中出现的附录A-C将成为许多读者的回顾。
